{"cells":[{"outputs":[{"output_type":"stream","text":"ls: cannot access '/home/kesci/input/': No such file or directory\r\n","name":"stdout"}],"execution_count":1,"source":"# 查看当前挂载的数据集目录\n!ls /home/kesci/input/","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"9BD2C073C9A045F58A70A8B6C1786B23","scrolled":false}},{"outputs":[{"output_type":"stream","text":"lost+found  negmas_scml\r\n","name":"stdout"}],"execution_count":12,"source":"# 查看个人持久化工作区文件\n!ls /home/kesci/work/","cell_type":"code","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"27927F582F234E92ACD402A76224E87F","scrolled":false}},{"metadata":{"id":"5C6053EE8A6C44B2BAF416CB6852B9A7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"# Advanced Negotiation \n## Modeling\n\nImplemente the model in Negmas \n\nVersion -- 21.Jul.2020\n\ntransfer the rlboa framework into the package negmas/modeling\n\nfilesystem structure\n\n\\negmas\n\t\\modeling\n\t\t\\rlboa\n\t\t\t\\boaframework\n\t\t\tabstract_state.py\n\t\t\tstate.py\n\t\t\trlboa.py\n\t\t\trlboa_agent.py\n\t\t\tqlearner.py\n\t\tacceptance_modeling.py\n\t\tutility.py\n\t\tstrategy.py\n\t\tfuture.py\n\n"},{"metadata":{"id":"4F47A607FB1D4BC180B842B11EA05A84","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Collecting gym\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b3/99/7cc3e510678119cdac91f33fb9235b98448f09a6bdf0cafea2b108d9ce51/gym-0.17.2.tar.gz (1.6MB)\n\u001b[K    100% |████████████████████████████████| 1.6MB 853kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from gym)\nRequirement already satisfied: numpy>=1.10.4 in /opt/conda/lib/python3.6/site-packages (from gym)\nCollecting pyglet<=1.5.0,>=1.4.0 (from gym)\n  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/70/ca/20aee170afe6011e295e34b27ad7d7ccd795faba581dd3c6f7cec237f561/pyglet-1.5.0-py2.py3-none-any.whl (1.0MB)\n\u001b[K    100% |████████████████████████████████| 1.0MB 1.3MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /opt/conda/lib/python3.6/site-packages (from gym)\nRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from pyglet<=1.5.0,>=1.4.0->gym)\nBuilding wheels for collected packages: gym\n  Running setup.py bdist_wheel for gym ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/kesci/.cache/pip/wheels/e2/f5/f5/3791255957de1b1e9b33a24419443c70334501bb1001b0372f\nSuccessfully built gym\nInstalling collected packages: pyglet, gym\nSuccessfully installed gym-0.17.2 pyglet-1.5.0\n\u001b[33mYou are using pip version 9.0.1, however version 20.2 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}],"source":"!pip install gym -i https://pypi.tuna.tsinghua.edu.cn/simple","execution_count":1},{"metadata":{"id":"88805FB66EB949CFAF53E509DFB05429","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Help on class Box in module gym.spaces.box:\n\nclass Box(gym.spaces.space.Space)\n |  A (possibly unbounded) box in R^n. Specifically, a Box represents the\n |  Cartesian product of n closed intervals. Each interval has the form of one\n |  of [a, b], (-oo, b], [a, oo), or (-oo, oo).\n |  \n |  There are two common use cases:\n |  \n |  * Identical bound for each dimension::\n |      >>> Box(low=-1.0, high=2.0, shape=(3, 4), dtype=np.float32)\n |      Box(3, 4)\n |  \n |  * Independent bound for each dimension::\n |      >>> Box(low=np.array([-1.0, -2.0]), high=np.array([2.0, 4.0]), dtype=np.float32)\n |      Box(2,)\n |  \n |  Method resolution order:\n |      Box\n |      gym.spaces.space.Space\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __eq__(self, other)\n |      Return self==value.\n |  \n |  __init__(self, low, high, shape=None, dtype=<class 'numpy.float32'>)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  contains(self, x)\n |      Return boolean specifying if x is a valid\n |      member of this space\n |  \n |  from_jsonable(self, sample_n)\n |      Convert a JSONable data type to a batch of samples from this space.\n |  \n |  is_bounded(self, manner='both')\n |  \n |  sample(self)\n |      Generates a single random sample inside of the Box.\n |      \n |      In creating a sample of the box, each coordinate is sampled according to\n |      the form of the interval:\n |      \n |      * [a, b] : uniform distribution\n |      * [a, oo) : shifted exponential distribution\n |      * (-oo, b] : shifted negative exponential distribution\n |      * (-oo, oo) : normal distribution\n |  \n |  to_jsonable(self, sample_n)\n |      Convert a batch of samples from this space to a JSONable data type.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __hash__ = None\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from gym.spaces.space.Space:\n |  \n |  __contains__(self, x)\n |  \n |  seed(self, seed=None)\n |      Seed the PRNG of this space.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from gym.spaces.space.Space:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n","name":"stdout"}],"source":"'''\n[]\nobsver_space = spaces.Dict(\n{\"X_best\": None, \"T_left\": None, \n\"IP_my\": None, \"RP_my\": None, \"S_neg\": None})\n'''\n\nimport gym\nfrom gym.spaces import Box\nhelp(gym.spaces.Box)\n# k = Box(low=-1.0, high=2.0, shape=(3, 4), dtype=np.float32)","execution_count":12},{"metadata":{"id":"4A8DA8DEC5A04EEA884D3DF5C5F6CC7C","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([401.2926 , 191.68828, 327.87628, 525.7085 ], dtype=float32)"},"transient":{},"execution_count":33}],"source":"'''\nFor example Issue ={'laptop_price'}\n\nIP_b [300 − 350]\nRP_b [500 − 550]\nIP_s 100%[500 − 550], 60%[580 − 630], 10%[680 − 730]\nRP_s 100%[300 − 350], 60%[380 − 430], 10%[480 − 530]\nMD_H{30, 40, 50}, A{18, 23, 28}, L{8, 10, 12}\nMR_H{10:1, 1:1, 1:10}, A{5:1, 1:1, 1:5}, L{2:1, 1:1, 1:2}\nt_end Lg[151s –210s], A[91s –150s], Sh[30s –90s]\nZoA H(100%), A(60%), L(10%)\n\nobsver_space = spaces.Dict(\n{\"X_best\": None, \"T_left\": None, \n\"IP_my\": None, \"RP_my\": None, \"S_neg\": None})\n\nX_best: the minimum offer offered by opponent.\n\nA possible observation space:\n[[300$ - 550$], [151s - 210s], [300$ - 350$], [500$ - 550$], [0 - 5]]\n\nExample\n[400, 160, 330, 530, 2]\nFirst we just consider a simple negotiation scenario, in other words, a simple negotiation settings\nIssue = {'laptop_price'}\nIP_b = [300 - 350]\nRP_b = [500 - 550]\nIP_s = [500 - 550]\nRP_b = [300 - 350]\nMD   = [2]\nMR   = [1:1]\nt_end = [151s - 210s]\nZoA = H(100%)\nas considered by paper 'A Deep Reinforcement Learning Approach to Concurrent Bilateral Negotiation'\n\na possible observation state is [350$, 20s, 340$, 530$, 2]\na possible action is a new offer outcome \n'''\n\nimport numpy as np\nfrom gym import spaces\nobservation_space = Box(low=np.array([300, 151, 300, 500]), high=np.array([550, 210, 350, 550]), dtype=np.float32)\n\nobservation_space.sample()","execution_count":33},{"metadata":{"id":"84122A7B66204C5B82CAE1D5A046DF00","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"'''\nconvert the the action defined by negmas.Action to action space that obtained in Gym.spaces\n        actions that agent can select are [Offer(x), ResponseType.REJECT_OFFER, ResponseType.ACCEPT_OFFER, exit]\n        ResponseType.ACCEPT_OFFER\n        ResponseType.REJECT_OFFER, will be gived a chance to propose new offer. \n        ResponseType.END_NEGOTIATION\n        ResponseType.NO_RESPONSE, refuse to offer.\n        ResponseType.WAIT\n        \n        when call function respond_ and firstly get the action ResponseType.REJECT_OFFER, then will call the function proposal_ to \n        get the new offer, the final action in AnegmaEnv is Offer(x)\n        \n        the logic has been described in the paper `A Deep Reinforcement learning approach to concurrent negotiation`\n        first condition: if just consider the propose, the action space is also a one dimensional box space for one issue.\n        second condition: if consider the response, the action space is [0, 1, 2, 3, 4]\n        \n        0: Offer(x): the outcome, if the response is ResponseType.REJECT_OFFER, the info sent to opponent is a offer\n        1: ResponseType.ACCEPT_OFFER\n        2: ResponseType.END_NEGOTIATION\n        3: ResponseType.NO_RESPONSE\n        4: WAIT\n        how to define the action_space\n        \n        first we consider the first condition, the action is the propose\n'''\n\naction_space = spaces.Box(low=np.array([300]), high=np.array([550]), dtype=np.float32) ","execution_count":35},{"metadata":{"id":"C541721B368B49C0824435A88DDFE5E2","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"0.5678369673327723"},"transient":{},"execution_count":40}],"source":"'''\nReward: \n    first condition: just consider the regression problem, means counter-offer, create a new offer\n    second confition: classfication problem, ResponseType.Accept, get a agreement, \n    ResponseType.No_RESPONSE or ResponseType.END_NEGOTIATION, other WAIT\n\nfor first condition, just calcualte the utility of new offer\n\n'''\nt_end = 500.0\ncurrent_t = 200.0\nd_t = 0.5\nstate =  observation_space.sample()\nx:\"new offer by my negotiator\" = 340\nreward = ((state[3] - x) / (state[3] - state[2])) * (current_t / t_end)**d_t\nreward = 0 # if the current_t greater than t_end\nreward = -1 # if the new offer is greater than  offer that created by opponent","execution_count":40},{"metadata":{"id":"B85FE54C3F02498B8A05258660B1B7A0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}